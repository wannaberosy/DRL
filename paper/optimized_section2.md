# 摘要

本课题针对复杂多跳推理与知识检索任务中语言智能体面临的规划效率与信用分配难题，提出了一种融合蒙特卡洛树搜索与树结构差分奖励的语言智能体框架。该框架以树搜索为核心范式，将大语言模型的推理、行动与规划能力统一于结构化的搜索过程中。在节点扩展层面，框架支持基于上置信界（UCT）的快速筛选与完整蒙特卡洛树搜索（MCTS）的深度规划两种模式，并可根据任务特性动态切换。在信用分配层面，引入树结构差分奖励机制，通过同层兄弟节点间的相对优势估计替代传统的绝对奖励信号，有效抑制高噪声输出带来的梯度波动。实验在 HotpotQA、TriviaQA 与 SQuAD 等基准数据集上进行，结果表明该框架在固定迭代预算约束下相较于 ReAct 基线取得了显著的成功率提升，同时展现出更优的样本效率与收敛稳定性。

# 研究目标

本课题旨在突破当前语言智能体在有限计算预算下面临的高效规划与稳定信用分配两大技术瓶颈。具体研究目标包括：构建一套统一的语言智能体树搜索框架，使大语言模型能够在推理过程中系统性地探索多条候选路径，而非仅依赖贪心式的单路径生成；设计树结构差分奖励机制，解决并行节点扩展场景下传统绝对奖励信号导致的高方差与误导回传问题；在 HotpotQA、TriviaQA 与 SQuAD 等多跳问答与阅读理解任务上验证框架的有效性，实现相对于 ReAct 等序列式基线的显著性能提升；建立可复现的实验管线与评估体系，为后续在工具调用、知识检索等场景的扩展应用奠定基础。

# 研究内容

本课题的研究工作围绕"受限预算下语言智能体的高效规划与稳定信用分配"这一核心问题展开，在方法设计、算法实现与系统构建三个层面形成完整的技术方案。

在方法层面，本课题提出语言智能体树搜索框架作为统一的推理范式。不同于传统 ReAct 等序列式方法在每一步仅生成单一动作并顺序执行，该框架将语言模型的输出组织为树形结构：根节点表示初始问题状态，每个中间节点对应一个推理步骤或行动决策，子节点则代表该状态下的多种可能延续。这种结构化表示使得系统能够在单次求解过程中并行探索多条推理路径，通过节点评估与选择机制动态调整搜索方向，从而在不增加总体计算开销的前提下显著提升找到正确答案的概率。

在节点选择与扩展策略方面，框架集成了两种互补的机制。上置信界（UCT）策略通过平衡历史累积回报与访问频次来指导节点选择，在探索未充分访问的分支与利用已验证的高质量路径之间取得平衡；针对语言模型输出的高噪声特性，引入了动态探索系数以防止个别偶然高分样本导致的过早收敛。完整的蒙特卡洛树搜索则在扩展阶段引入模拟与价值评估环节，通过短程推演或价值网络估计预测候选路径的长期收益，为深层推理任务提供更稳健的决策依据。实践中，两种策略可根据搜索深度灵活调度：浅层采用 UCT 快速过滤低质量分支，深层切换至 MCTS 进行精细规划。

信用分配的稳定性是树搜索框架面临的核心挑战之一。当多个候选节点并行扩展时，传统基于绝对奖励的回传机制容易受到单个异常高分样本的干扰，导致后续搜索方向产生偏差。为此，本课题提出树结构差分奖励机制：在同一深度层级的兄弟节点之间构造相对优势而非使用原始分数，通过归一化处理消除批次间的尺度差异，使梯度信号更加稳定。该机制与批量扩展策略天然兼容，可在每轮迭代中以向量化方式高效计算，在提升信用分配精度的同时降低计算开销。

在系统实现层面，本课题构建了完整的实验管线与评估工具链。核心求解器模块封装了树搜索的完整流程，支持 UCT、MCTS 及混合模式的灵活配置；语言模型接口层提供与主流 API 服务的统一对接，内置请求重试与格式校验机制以保证长时间运行的稳定性；实验管理模块统一处理数据加载、预算控制与结果记录，所有配置参数与输出结果均以结构化格式持久化存储。评估体系覆盖成功率、平均求解迭代、样本效率等核心指标，并通过可视化模块生成跨数据集、跨配置的对比分析图表。

实验验证选取 HotpotQA、TriviaQA 与 SQuAD 三类代表性数据集，分别对应多跳事实推理与单段阅读理解等不同难度层级的任务。在统一的迭代与令牌预算约束下，系统性地对比不同扩展策略与奖励模式的效果差异，并通过消融实验考察分支数、模拟次数、差分奖励开关等关键因素的影响，以验证各技术组件的独立贡献与协同增益。

# 关键技术

本课题的技术贡献集中体现在以下几个方面。

**统一的树搜索推理框架**。该框架将语言模型的思维链与行动序列显式结构化为树形搜索空间，突破了传统序列式推理的单路径局限。在每次迭代中，系统从当前状态出发生成多条候选路径并以节点形式并行扩展，随后通过评估函数对节点进行打分，并将评估结果沿路径回传以形成对全局搜索方向的调控。这种机制使得系统能够在有限计算预算内同时覆盖多种推理假设，显著提升求解成功率。

**树结构差分奖励机制**。针对批量扩展场景下传统绝对奖励信号的高方差问题，该机制通过在兄弟节点间构造相对优势来指导信用分配。具体而言，对同一深度层级的候选节点计算归一化回报，以差分形式抑制偶然高分样本的影响，使梯度方向更加稳定。该技术可与 UCT 和 MCTS 两种扩展策略无缝集成，支持不同批量规模与搜索深度下的高效计算。

**自适应的扩展策略调度**。框架提供 UCT 与 MCTS 两种扩展模式的统一接口，并支持根据搜索进程动态切换。UCT 模式利用访问统计与置信上界实现快速的探索—利用平衡，适用于浅层的高效筛选；MCTS 模式通过模拟与价值评估提供对长期收益的稳健估计，适用于深层的精细规划。两种模式的协同调度使框架能够兼顾响应速度与决策质量。

**工程化的实验与评估体系**。完整的实验管线覆盖数据加载、配置管理、结果记录与可视化分析的全流程，所有实验均以结构化格式记录关键参数与输出，确保结果的可复现性与可审计性。评估模块支持成功率、样本效率、收敛曲线等多维度指标的自动计算与图表生成，为算法分析与论文撰写提供便捷支撑。

# 技术指标及指标分析

本课题围绕语言智能体树搜索框架的核心目标，从任务性能、推理效率、算法稳定性与工程可靠性四个维度构建技术指标体系，以全面刻画系统在不同场景下的表现特征。

## 任务性能指标

**成功率（Success Rate）** 是衡量框架有效性的核心指标，定义为在给定预算约束下正确回答问题的样本数占总测试样本数的比例。该指标直接反映了树搜索策略相对于序列式基线在复杂推理任务中的增益幅度。在 HotpotQA 等多跳问答任务中，由于需要整合多个文档片段的信息，成功率的提升尤为关键。本课题目标是在固定迭代预算（如 10 次迭代）下，相较于 ReAct 基线实现至少 15% 的绝对成功率提升。

**精确匹配率（Exact Match, EM）** 与 **F1 分数** 作为答案质量的细粒度度量，用于评估生成答案与标准答案的文本重合程度。EM 要求答案与标注完全一致，适用于事实型问答；F1 则综合考虑召回率与准确率，对部分匹配的情况给予适当得分。两者结合使用可避免单一指标的片面性。
## 算法稳定性指标

**回报方差（Reward Variance）** 量化同批次扩展节点间奖励信号的离散程度。传统绝对奖励机制下，高方差会导致梯度更新方向不稳定，进而影响搜索策略的收敛。树结构差分奖励机制的核心目标即是降低该指标，通过相对优势估计使信用分配更加鲁棒。本课题预期在启用差分奖励后，回报方差相较于绝对奖励模式降低 50% 以上。

**收敛稳定性（Convergence Stability）** 通过观察成功率随迭代预算增加的变化曲线来评估。理想的框架应表现出平滑上升且方差较小的收敛轨迹，而非剧烈波动或过早饱和。跨多次独立运行的结果一致性（通过标准差或置信区间量化）也是该指标的重要组成部分。

**跨数据集泛化性（Cross-Dataset Generalization）** 考察同一配置在不同类型任务（如多跳推理与单段阅读理解）上的表现差异。若框架在各数据集上均能保持稳定增益，则表明其具备良好的任务无关性，而非针对特定数据分布的过拟合。

## 工程可靠性指标

**运行成功率（Runtime Success Rate）** 统计长时间实验过程中因 API 异常、格式解析错误或超时等原因导致的失败比例。该指标反映系统的工程鲁棒性，目标是通过内置的重试机制与异常处理策略将非算法因素导致的失败率控制在 5% 以下。

**可复现性（Reproducibility）** 要求在相同配置与随机种子下，多次运行的结果差异在可接受范围内（如成功率浮动 ±2%）。完整的配置记录、结构化的结果存储与版本化的代码管理是保障该指标的基础。

**评估覆盖度（Evaluation Coverage）** 衡量评估体系对上述各类指标的支持程度。本课题构建的可视化模块能够自动生成成功率热力图、预算—性能曲线、迭代分布箱线图等多类图表，确保指标体系中的各项度量均有对应的分析工具。

## 指标体系综述

上述指标从不同角度刻画了语言智能体树搜索框架的能力边界。任务性能指标回答"能否解决问题"的核心问题；推理效率指标回答"以多大代价解决问题"；稳定性指标回答"能否可靠地解决问题"；工程指标回答"能否在实际环境中持续运行"。四类指标相互补充，共同构成评估框架综合表现的完整视角。在后续实验分析中，将依据该指标体系对各技术组件的贡献进行系统性量化，并通过消融实验验证各指标间的关联与权衡关系。
